{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notesync.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFK02pOMLgcv",
        "colab_type": "code",
        "outputId": "88011619-782a-4246-a7be-9a69b54b0ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Auto notebook (.ipynb) to python file convertor\n",
        "# The following code, when run from a notebook - starts a process on the VM of the notebooks\n",
        "# that copies all *.ipynb --> ./notepy/*.py\n",
        "# The script does that automatically.\n",
        "# USAGE\n",
        "# 1. Run this paragraph\n",
        "# 2. Create a new notebook - for example create test1.ipynb with print(\"Hellow world\") in it\n",
        "# 3. import notepy.test1\n",
        "# You will see \"Hello world\" as a result of the import\n",
        "# _APACHE_SPARK_ \n",
        "# If you are using Apache Spark:\n",
        "#     you can add the module file to spark with the code:\n",
        "#     sc.addPyFile(notepy.test1.__file__)\n",
        "# _GOOGLE_COLAB_\n",
        "# If you are using Google Colab\n",
        "#     Script will try to mount your drive and as for login\n",
        "#     Script assume notebooks are under \"/content/drive/My Drive/Colab Notebooks\"\n",
        "#     It adds this to sys.path which allows same usage (as above):\n",
        "#     import notepy.test1\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "\n",
        "\n",
        "def paragraph_to_py_module(py_filename, spark_context=None, src_text=None, paragraph_index=-2):\n",
        "    \"\"\"Write the last evaluated notebook paragraph to a file and send to executors\"\"\"\n",
        "    if src_text is None:\n",
        "        src_text = In[paragraph_index]  # last paragraph==-2\n",
        "    with open(py_filename, \"w+t\") as out_py:\n",
        "        out_py.write(src_text)\n",
        "    if spark_context:\n",
        "        spark_context.addPyFile(py_filename)\n",
        "\n",
        "\n",
        "def relative_path(root_dir, dirpath, f):\n",
        "    \"\"\"get the relative part of a file name \"\"\"\n",
        "    full = os.path.join(dirpath, f)\n",
        "    if not root_dir:\n",
        "        return full\n",
        "    if not full.startswith(root_dir):\n",
        "        print(\"ERROR - bad path for root\", full)\n",
        "        return None\n",
        "    full = full[len(root_dir):]\n",
        "    if full.startswith(\"/\"):\n",
        "        return full[1:]\n",
        "    return full\n",
        "\n",
        "\n",
        "def is_ipython():\n",
        "    \"\"\"check if running inside a notebook\"\"\"\n",
        "    return 'get_ipython' in globals()\n",
        "\n",
        "\n",
        "def ipython_kind():\n",
        "    if not is_ipython():\n",
        "        return None\n",
        "    if \"google.colab._shell.Shell\" in str(get_ipython()):\n",
        "        return \"google_colab\"\n",
        "    if \"spark\" in globals():\n",
        "        if \"dbutils\" in globals():\n",
        "            return \"spark_databricks\"\n",
        "        return \"spark\"\n",
        "    return \"unknown_ipython\"\n",
        "\n",
        "\n",
        "def google_colab_login_if_needed():\n",
        "    gcolab_root = '/content/drive'\n",
        "    if os.path.isdir(gcolab_root):\n",
        "        return\n",
        "    print(\"Need AUTH - mounting G-drive to access notebooks to export .ipynb->.py\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "def do_system(cmd):\n",
        "    print(\"Executing: \", cmd)\n",
        "    if is_ipython():\n",
        "        get_ipython().system_raw(cmd)\n",
        "    else:\n",
        "        os.system(cmd)\n",
        "    \n",
        "    \n",
        "def iter_relative_path_recursive(root_dir):\n",
        "    # generate all files in the directories under root_dir\n",
        "    # generate names relative to root_dir\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f in filenames:\n",
        "            filename = relative_path(root_dir, dirpath, f)\n",
        "            yield filename\n",
        "\n",
        "            \n",
        "def iter_relative_path(root_dir):\n",
        "    for fname in os.listdir(root_dir):\n",
        "        fullpath = os.path.join(root_dir, fname)\n",
        "        if os.path.isdir(fullpath):\n",
        "            continue\n",
        "        yield fname\n",
        "\n",
        "        \n",
        "def iter_merge_infinite_loop(iter_builder1, iter_builder2):\n",
        "    it1 = iter_builder1()\n",
        "    it2 = iter_builder2()\n",
        "    while True:\n",
        "        try:\n",
        "            x = it1.__next__()\n",
        "            yield x\n",
        "        except (StopIteration, RuntimeError):\n",
        "            it1 = iter_builder1()\n",
        "        try:\n",
        "            x = it2.__next__()\n",
        "            yield x\n",
        "        except (StopIteration, RuntimeError):\n",
        "            it2 = iter_builder2()\n",
        "\n",
        "            \n",
        "py_code_footer = \"\"\"\n",
        "__g_reload_module_called = False\n",
        "__reload = None\n",
        "def rerun_module(context=None):\n",
        "    global __g_reload_module_called\n",
        "    global __reload\n",
        "    # context used for things like spark context\n",
        "    if not __reload:\n",
        "        try:\n",
        "            __reload = reload  # v2.7\n",
        "        except:\n",
        "            pass\n",
        "    if not __reload:\n",
        "        try:\n",
        "            import imp\n",
        "            __reload = imp.reload  # v3.2\n",
        "        except:\n",
        "            pass\n",
        "    if not __reload:\n",
        "        try:\n",
        "            import importlib\n",
        "            __reload = importlib.reload  # v3.4+\n",
        "        except:\n",
        "            pass\n",
        "    if not __g_reload_module_called:\n",
        "        __g_reload_module_called = True\n",
        "        return  # on the first import - code already executed.\n",
        "    # reload this module\n",
        "    import sys\n",
        "    new_self = __reload(sys.modules[__name__])\n",
        "    new_self.__g_reload_module_called = True    \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "py_code_footer_spark = py_code_footer + \"\"\"\n",
        "    if context and hasattr(context, \"sparkContext\"):\n",
        "        global spark\n",
        "        global sc\n",
        "        spark = context\n",
        "        sc = context.sparkContext\n",
        "        sc.addPyFile(__file__)\n",
        "\"\"\"\n",
        "            \n",
        "def copy_note_to_py(note_full_path, note_name, dst_dir, kind):\n",
        "    #\n",
        "    dst_py = re.sub(r\"(\\.ipynb)?$\", \".py\", note_full_path) # file created by convert\n",
        "    cmd = \"jupyter nbconvert --to python {}\".format(note_full_path)\n",
        "    do_system(cmd)\n",
        "    # now append extra code to py\n",
        "    footer = py_code_footer\n",
        "    if kind.startswith('spark'):\n",
        "        footer = py_code_footer_spark\n",
        "    with open(dst_py, \"a+t\") as pyfile:\n",
        "        pyfile.write(footer)\n",
        "    py_name = os.path.split(dst_py)[1]\n",
        "    os.rename(dst_py, os.path.join(dst_dir, py_name))\n",
        "    \n",
        " \n",
        "def create_notepy_dir_if_needed(parent_dir=\".\"):\n",
        "    dst_dir = os.path.join(parent_dir, \"notepy\")\n",
        "    if not os.path.isdir(dst_dir):\n",
        "          os.mkdir(dst_dir)\n",
        "\n",
        "    \n",
        "def copy_local_notes_to_py(src_dir=\".\", kind=\"\", dst_dir=None, exclude_notes=[]):\n",
        "    if not dst_dir:\n",
        "        dst_dir = os.path.join(src_dir, \"notepy\")\n",
        "        if not os.path.isdir(dst_dir):\n",
        "            os.mkdir(dst_dir)\n",
        "        \n",
        "    files_attr = {}\n",
        "\n",
        "    def handle_file(filename):\n",
        "        # return True, mtime if file needed upload\n",
        "        # return False if not\n",
        "        nonlocal files_attr\n",
        "        now = int(time.time())\n",
        "        full = os.path.join(src_dir, filename)\n",
        "        if not os.path.exists(full):\n",
        "            #file may have been deleted\n",
        "            return False, now  # just ignore - not handling deletes\n",
        "        mtime = os.path.getmtime(full)\n",
        "        client_first_look = False\n",
        "        if filename in files_attr:\n",
        "            last_mtime = files_attr[filename][\"mtime\"]\n",
        "            if mtime <= last_mtime:\n",
        "                return False, mtime\n",
        "        else:\n",
        "            files_attr[filename] = {}\n",
        "            client_first_look = True\n",
        "        files_attr[filename][\"mtime\"] = mtime\n",
        "        copy_note_to_py(full, filename, dst_dir, kind)\n",
        "        return True, mtime        \n",
        "        \n",
        "    log_count = 0\n",
        "    speed=1.0\n",
        "    recently_changed = {}\n",
        "    for filename in iter_merge_infinite_loop(lambda : iter_relative_path(src_dir),\n",
        "                                             lambda: iter(recently_changed.keys())):\n",
        "        if not filename.endswith(\".ipynb\"):\n",
        "            continue\n",
        "        if filename in exclude_notes:\n",
        "            continue\n",
        "        time.sleep(0.1 * speed)\n",
        "        speed = min(max(speed * 1.05, 0), 1.0) # slow down\n",
        "        log_count += 1\n",
        "        if log_count >= 50:\n",
        "            # dilute the log by X50 to preven too much output\n",
        "            print(\"Checking file \", filename)\n",
        "            log_count = 0\n",
        "        updated, mtime = handle_file(filename)\n",
        "        if updated:\n",
        "            recently_changed[filename] = mtime\n",
        "            # if updated - accelerate\n",
        "            speed /= 2.0\n",
        "        else:\n",
        "            # check if need to remove from recently changed\n",
        "            if filename in recently_changed and time.time() - mtime > 5 * 60:\n",
        "                del recently_changed[filename]\n",
        "\n",
        "\n",
        "def kill_prev_script(ps_pattern):\n",
        "    pid = os.getpid()                                     \n",
        "    do_system(\"ps ax | grep notesync.py | grep -v grep | awk '{print $1}'| grep -v %s | xargs kill \" % pid)\n",
        "\n",
        "\n",
        "def mount_cd_to_notebooks():\n",
        "    cd_cmd = \"\"\n",
        "    kind = ipython_kind()\n",
        "    if kind == \"google_colab\":\n",
        "        google_colab_login_if_needed()\n",
        "        colab_root = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "        os.chdir(colab_root)\n",
        "        if not colab_root in sys.path:\n",
        "            # script will create \"notepy\" under colab_root\n",
        "            #this allows importing from notepy.MYNOTEBOOK\n",
        "            sys.path.append(colab_root)\n",
        "    elif kind == \"spark_databricks\":\n",
        "        # TODO(franji): find how to access the notebooks in databricks\n",
        "        pass\n",
        "    \n",
        "\n",
        "def main():\n",
        "    if sys.platform == \"win32\":\n",
        "        raise NotImplemented(\"Windows is not supported at this stage\")\n",
        "    if is_ipython():\n",
        "        save_dir = os.getcwd()\n",
        "        mount_cd_to_notebooks()  # cd into notebook root dir\n",
        "        # running in main notebook - save this paragraph to a py file\n",
        "        create_notepy_dir_if_needed()\n",
        "        paragraph_to_py_module(\"notepy/notesync.py\", paragraph_index=-1)\n",
        "        # now run myself on the notebook machine machine\n",
        "        kind = ipython_kind() or \"unknown\"\n",
        "        # Call myself (notesync.py) with 'kind' parameter.\n",
        "        # TODO(franji): fix the case where 'spark' variable is not defined yet\n",
        "        #    when this code is called (e.g. creating a session in the notebook code)\n",
        "        do_system(\"python3 notesync.py %s &\" % kind)\n",
        "        os.chdir(save_dir)  # restore\n",
        "        print(\"\"\"\n",
        "        Notebooks code is mirroored under notepy.*\n",
        "        Now you can put function in separate notebook anduse python import\n",
        "        #For example:\n",
        "        _\n",
        "        import notepy.my_util_notebook\n",
        "        -\n",
        "        #To reload/rerun module use:\n",
        "        -\n",
        "        my_util_notebook.rerun_module()\n",
        "        _\n",
        "        If you use Apache Spark notebook use my_util_notebook.rerun_module(spark)\n",
        "        the file my_util_notebook.ipynb is exporterd to notepy/my_util_notebook.py\n",
        "        automatically.\n",
        "        \"\"\")\n",
        "    else:\n",
        "        # in main but not in notebook - in a script\n",
        "        kill_prev_script(\"notesync.py\")\n",
        "        kind = \"\"\n",
        "        if len(sys.argv) > 1:\n",
        "            kind = sys.argv[1]\n",
        "        copy_local_notes_to_py(kind=kind, exclude_notes=[\"notesync.ipynb\"])\n",
        "\n",
        "\n",
        "# Some util function unrelated to notebook->py mirroring\n",
        "#def globals - a \"macro\" allowing putting all the imports in \n",
        "#  one function of another module/notebook\n",
        "class DefGlobals(Exception):\n",
        "    pass\n",
        "\n",
        "def def_globals(f):\n",
        "    \"\"\"\n",
        "    Decorator to allow putting global imports into a function.\n",
        "    This allows putting common imports in on module/notebook and calling it from another.\n",
        "    Fumnction must and by calling raise DefGlobals()\n",
        "    >>> import notepy.notesync\n",
        "    >>> @notesync.def_globals\n",
        "    ... def import_all():\n",
        "    ...     import sklearn\n",
        "    ...     import numpy as np\n",
        "    ...     import pandas as pd\n",
        "    ...     raise notesync.DefGlobals()\n",
        "    ...\n",
        "    >>> import_all(globals())\n",
        "    >>> pd\n",
        "    <module 'pandas' from '/dist/lib/python3.7/site-packages/pandas/__init__.py'>\n",
        "\n",
        "    \"\"\"\n",
        "    import sys\n",
        "    def wrapped_f(global_ref):\n",
        "        try:\n",
        "            f()\n",
        "            raise ValueError(\"ERROR def_globals: 'raise DefGlobals()' must be called!\")\n",
        "        except DefGlobals as dge:\n",
        "            frame = sys.exc_info()[2]\n",
        "            # goto inner function frame\n",
        "            frame = frame.tb_next.tb_frame\n",
        "            inner_locals = frame.f_locals\n",
        "            # copy local variables (e.g. imported modules) \n",
        "            # into global space\n",
        "            for k,v in inner_locals.items():\n",
        "                global_ref[k] = v            \n",
        "    return wrapped_f\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing:  python3 notesync.py google_colab &\n",
            "\n",
            "        Notebooks code is mirroored under notepy.*\n",
            "        Now you can put function in separate notebook anduse python import\n",
            "        #For example:\n",
            "        _\n",
            "        import notepy.my_util_notebook\n",
            "        -\n",
            "        #To reload/rerun module use:\n",
            "        -\n",
            "        my_util_notebook.rerun_module()\n",
            "        _\n",
            "        If you use Apache Spark notebook use my_util_notebook.rerun_module(spark)\n",
            "        the file my_util_notebook.ipynb is exporterd to notepy/my_util_notebook.py\n",
            "        automatically.\n",
            "        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qw-lLzhxSL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}